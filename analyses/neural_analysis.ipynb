{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f29250f-1b08-43e7-9993-bc903cd27140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3bfd58-1d98-48c3-b646-1a30e5694415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of all 100 clips into a list\n",
    "\n",
    "clip_path = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/movie_clips/\"\n",
    "clip_dir = os.listdir(clip_path)\n",
    "movie_list = [x for x in clip_dir if '.' not in x] #generates a list of all 10 movies\n",
    "clip_list = []\n",
    "\n",
    "zip_name, zip_start, zip_stop = [],[],[]\n",
    "\n",
    "\n",
    "for movie in movie_list:\n",
    "    clips = [x for x in os.listdir(clip_path+movie) if 'mp4' in x]\n",
    "    \n",
    "    for clip in clips:\n",
    "        name = clip.split('.')[0]\n",
    "        start = name.split('_')[1]\n",
    "        stop = name.split('_')[2]\n",
    "        clip_list.append(name)\n",
    "\n",
    "        zip_name.append(name)\n",
    "        zip_start.append(start)\n",
    "        zip_stop.append(stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36017c71-c780-4826-910c-599c41b2b802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clip_dict = dict(zip(zip_name, zip(zip_start, zip_stop)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6d79039-585b-451c-9b27-2bfc5aa5cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the participant .nii files\n",
    "\n",
    "img_path = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/data_fmri/\"\n",
    "out_path = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/analyses/trimmed_fmri/\"\n",
    "func_data = os.listdir(img_path)\n",
    "sub_data = [x for x in func_data if ('sub-') in x] #grab all the subject IDs for easy filtering\n",
    "\n",
    "#make a sub-directory for each subject's trimmed nii files\n",
    "# for sub in sub_data:\n",
    "#     sub_id = sub.split('_')[0]\n",
    "#     os.mkdir(out_path+sub_id)\n",
    "\n",
    "# len(sub_data) # 86\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939dc524-d0b2-4df0-8c21-b57e64a6a883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "936ce050-ca01-4f7a-bea5-96a5033577eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie in movie_list[0:1]:\n",
    "    sub_clips = [x for x in clip_list if movie in x]\n",
    "    sub_subs =  [x for x in sub_data if movie in x]\n",
    "\n",
    "    for sub in sub_subs[0:1]:\n",
    "        sub_id = sub.split('_')[0]\n",
    "        img = nb.load(img_path+sub)\n",
    "        for clip in sub_clips[0:1]:\n",
    "            start = int(clip_dict[clip][0]) - 4\n",
    "            stop = int(clip_dict[clip][1]) + 4\n",
    "            #clip_slice = img.slicer[:,:,:,start:stop]\n",
    "\n",
    "            fname = sub_id+os.sep+sub_id+\"_\"+movie+\"_\"+str(start)+\"_\"+str(stop)\n",
    "            nb.save(clip_slice, out_path+fname+\".nii.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca1bd5-9234-4524-a16d-cf728207c4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "804ee6e9-9beb-4476-a070-621a6da711e8",
   "metadata": {},
   "source": [
    "## Apply schaefer atlas to clipped nii files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174103ba-5726-4339-a385-d36ba1918012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "import nilearn\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting\n",
    "import nilearn.image as image\n",
    "from nilearn.maskers import NiftiMasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12572c62-2440-4add-a5fb-bb6875f5d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schaefer_atlas = datasets.fetch_atlas_schaefer_2018(n_rois=100, yeo_networks=17, resolution_mm=1,\n",
    "                                                    data_dir=None, base_url=None, resume=True, verbose=1)\n",
    "'''\n",
    "From the documentation:\n",
    "The list of labels does not contain ‘Background’ by default. \n",
    "To have proper indexing, you should either manually add ‘Background’ to the list of labels:\n",
    "'''\n",
    "\n",
    "schaefer_atlas.labels = np.insert(schaefer_atlas.labels, 0, \"Background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2c5b7d-5111-424a-b23e-9905d1c4546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_path = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/analyses/trimmed_fmri/sub-71/sub-71_split_5605_5637.nii.gz\"\n",
    "clip_slice = nb.load(clip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9263b6b2-69cc-4b53-a6f2-94e0776313ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_avg = image.mean_img(clip_slice) #shape is (64, 76, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1af25676-6c02-4575-a30c-a4376f0c5ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2238211  -0.14392954 -0.2006803  ... -2.6160626  -4.0625095\n",
      "  -2.814539  ]] (1, 9158)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2397058   0.30108017  0.33360443 ... -1.3313439  -1.2829909\n",
      "  -1.2636914 ]] (1, 12663)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.52525437 -0.3709902  -0.16731267 ... -0.00613056 -0.00199834\n",
      "  -0.01979208]] (1, 7576)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12065879 0.17848925 0.1699716  ... 0.42132995 0.37926275 0.37456697]] (1, 14834)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5): #start with 1 to ignore the background.\n",
    "    parcel = nilearn.image.new_img_like(schaefer_atlas.maps, nilearn.image.get_data(schaefer_atlas.maps) == i)\n",
    "    masker = NiftiMasker()\n",
    "    parcel_mask = masker.fit(parcel)\n",
    "    roi_data = parcel_mask.transform_single_imgs(clip_avg)\n",
    "    print(roi_data,roi_data.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c5459c-d8eb-4448-a7dd-9ed9d6e64868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
