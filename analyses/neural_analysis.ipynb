{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29250f-1b08-43e7-9993-bc903cd27140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3bfd58-1d98-48c3-b646-1a30e5694415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of all 100 clips into a list\n",
    "\n",
    "clip_path = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/movie_clips/\"\n",
    "clip_dir = os.listdir(clip_path)\n",
    "movie_list = [x for x in clip_dir if '.' not in x] #generates a list of all 10 movies\n",
    "clip_list = []\n",
    "\n",
    "zip_name, zip_start, zip_stop = [],[],[]\n",
    "\n",
    "\n",
    "for movie in movie_list:\n",
    "    clips = [x for x in os.listdir(clip_path+movie) if 'mp4' in x]\n",
    "    \n",
    "    for clip in clips:\n",
    "        name = clip.split('.')[0]\n",
    "        start = name.split('_')[1]\n",
    "        stop = name.split('_')[2]\n",
    "        clip_list.append(name)\n",
    "\n",
    "        zip_name.append(name)\n",
    "        zip_start.append(start)\n",
    "        zip_stop.append(stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36017c71-c780-4826-910c-599c41b2b802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clip_dict = dict(zip(zip_name, zip(zip_start, zip_stop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d79039-585b-451c-9b27-2bfc5aa5cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the participant .nii files\n",
    "\n",
    "#img_path = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/data_fmri/\"\n",
    "derivative_path = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/derivatives/\"\n",
    "#func_data = os.listdir(img_path)\n",
    "#sub_data = [x for x in func_data if ('sub-') in x] #grab all the subject IDs for easy filtering\n",
    "\n",
    "# make a sub-directory for each subject's trimmed nii files -- DONE\n",
    "# for sub in sub_data:\n",
    "#     sub_id = sub.split('_')[0]\n",
    "#     os.mkdir(out_path+sub_id)\n",
    "\n",
    "#len(sub_data) # 86\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb854e39",
   "metadata": {},
   "source": [
    "For each subject, we want to trim out separate files that correspond to the moments that they watched the social interaction clips we selected for further analysis. We add 4 seconds to the beginning and end of the fMRI timeseries to account for the hemodynamic response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ce050-ca01-4f7a-bea5-96a5033577eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE\n",
    "\n",
    "# for movie in movie_list:\n",
    "#     sub_clips = [x for x in clip_list if movie in x]\n",
    "#     sub_subs =  [x for x in sub_data if movie in x]\n",
    "\n",
    "#     for sub in sub_subs:\n",
    "#         sub_id = sub.split('_')[0]\n",
    "#         img = nb.load(img_path+sub)\n",
    "#         for clip in sub_clips:\n",
    "#             start = int(clip_dict[clip][0]) - 4\n",
    "#             stop = int(clip_dict[clip][1]) + 4\n",
    "#             clip_slice = img.slicer[:,:,:,start:stop]\n",
    "\n",
    "#             fname = sub_id+\"_\"+movie+\"_\"+str(start)+\"_\"+str(stop)\n",
    "#             nb.save(clip_slice, out_path+sub_id+os.sep+fname+\".nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804ee6e9-9beb-4476-a070-621a6da711e8",
   "metadata": {},
   "source": [
    "## <font color='deeppink'>Apply schaefer atlas to clipped nii files</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "174103ba-5726-4339-a385-d36ba1918012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "import nilearn\n",
    "from nilearn import datasets\n",
    "import nilearn.image as image\n",
    "from nilearn.maskers import NiftiMasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12572c62-2440-4add-a5fb-bb6875f5d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schaefer_atlas = datasets.fetch_atlas_schaefer_2018(n_rois=400, yeo_networks=17, resolution_mm=1,\n",
    "                                                    data_dir=None, base_url=None, resume=True, verbose=1)\n",
    "'''\n",
    "From the documentation:\n",
    "The list of labels does not contain ‘Background’ by default. \n",
    "To have proper indexing, you should either manually add ‘Background’ to the list of labels:\n",
    "'''\n",
    "\n",
    "schaefer_atlas.labels = np.insert(schaefer_atlas.labels, 0, \"Background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b900ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = os.listdir(derivative_path)\n",
    "sub_list = [x for x in sub_list if 'sub' in x] #remove hidden files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a sub-directory for each subject's parcel  matrices--DONE\n",
    "\n",
    "# for sub in sub_list:\n",
    "#     try:\n",
    "#         os.mkdir(derivative_path+sub+os.sep+\"parcel_matrix\")\n",
    "#     except:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a477b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holding all 400 parcel masks in memory; takes apprx 2m13s\n",
    "mask_list = []\n",
    "\n",
    "for p in range(1,402): #402\n",
    "\n",
    "    try:\n",
    "        parcel = nilearn.image.new_img_like(schaefer_atlas.maps, nilearn.image.get_data(schaefer_atlas.maps) == p) #hold the parcel masks in memory \n",
    "        masker = NiftiMasker() \n",
    "\n",
    "        parcel_mask = masker.fit(parcel)\n",
    "        mask_list.append(parcel_mask)\n",
    "    \n",
    "    except: \n",
    "        print(\"out of range, p=\", p)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23bbab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sub_list[0:1]: #20 min per subject\n",
    "    print(\"Starting with subject: \", s)\n",
    "    sub_clips = os.listdir(derivative_path+s)\n",
    "    sub_clips = [x for x in sub_clips if 'sub' in x]\n",
    "    sub_clips.sort() # super important, it has to be in ascending order. \n",
    "\n",
    "    for c in sub_clips[1:]: #2m 13s per clip\n",
    "        clip_slice = nb.load(derivative_path+s+os.sep+c)\n",
    "        clip_avg = image.mean_img(clip_slice)\n",
    "\n",
    "        clip_name = c.replace('.', '_')\n",
    "        clip_name = clip_name.split('_')[1:4]\n",
    "        clip_name = \"_\".join(clip_name)\n",
    "\n",
    "        data_list = []\n",
    "\n",
    "        for ix,mask in enumerate(mask_list):\n",
    "            try:\n",
    "                roi_data = mask.transform_single_imgs(clip_avg)\n",
    "                data_list.append(roi_data[0])\n",
    "            except:\n",
    "                print(\"index: \", ix)\n",
    "                continue\n",
    "\n",
    "        df = pd.DataFrame(data_list)\n",
    "        df.to_csv(derivative_path+s+os.sep+\"clip_voxels/\"+str(clip_name)+\".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47685a",
   "metadata": {},
   "source": [
    "# <font color='deeppink'>Creating Similartiy Matrices</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ea873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f13274",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/derivatives/\"\n",
    "\n",
    "sub_list = os.listdir(derivatives)\n",
    "sub_list = [x for x in sub_list if 'sub' in x] #remove hidden files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2355a",
   "metadata": {},
   "source": [
    "<font color='deeppink'>Create a 10x10 similarity matrix: </font> for each parcel, I want to create a similarity matrix among all the 10 clips the participant watched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c511e2-c627-40c0-844b-64a3e94348a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sub_list:\n",
    "    print(\"correlating: \", s)\n",
    "    spath = derivatives+s+'/clip_voxels/'\n",
    "    parcel_list = [x for x in  os.listdir(spath) if '.csv' in x]\n",
    "\n",
    "    df_list = [pd.read_csv(spath+x) for x in parcel_list]\n",
    "\n",
    "    for i in range(len(df_list[0])): #0,1,...400 for each row\n",
    "\n",
    "        mat = pd.DataFrame()\n",
    "\n",
    "        for ix, df in enumerate(df_list): # go into each df \n",
    "            voxels = df.iloc[i]\n",
    "            mat[parcel_list[int(ix)]] = voxels\n",
    "\n",
    "        mat.dropna(inplace=True)\n",
    "        distance_matrix = pd.DataFrame(pairwise_distances(mat.T, metric='correlation'))\n",
    "\n",
    "        distance_matrix.to_csv(derivatives+s+'/parcel_matrix/'+str(i)+\"_correlation.csv\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138eb834",
   "metadata": {},
   "source": [
    "<font color='deeppink'>Import the 100x100 behavioral distance matrix.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a684f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nilearn\n",
    "import statsmodels.api as sm\n",
    "from nilearn.connectome import ConnectivityMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "850baf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/derivatives/\"\n",
    "\n",
    "sub_list = os.listdir(derivatives)\n",
    "sub_list = [x for x in sub_list if 'sub' in x] #remove hidden files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "023e99cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conflict_distance_matrix.csv\n",
      "watched_distance_matrix.csv\n",
      "count_people_distance_matrix.csv\n",
      "violence_distance_matrix.csv\n",
      "count_interactions_distance_matrix.csv\n",
      "feeling_distance_matrix.csv\n",
      "tension_distance_matrix.csv\n",
      "social_distance_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "iv_list = []\n",
    "\n",
    "for x in os.listdir(derivatives+\"behavioral_matrices\"):\n",
    "    if '.csv' in x:\n",
    "        print(x)\n",
    "        df = pd.read_csv(derivatives+\"behavioral_matrices/\"+x)\n",
    "        iv_list.append(df)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ed0048",
   "metadata": {},
   "source": [
    "First, check if there is co-linearity between the IV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4827842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c04e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1073f31b",
   "metadata": {},
   "source": [
    "### <font color='hotpink'> next, model the DVs matrices.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9388366f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-11\n"
     ]
    }
   ],
   "source": [
    "for s in sub_list[63:64]:\n",
    "    print(s)\n",
    "    spath = derivatives+s\n",
    "    smovielist = [x for x in os.listdir(spath) if 'sub' in x]\n",
    "    smovie = smovielist[0].split('_')[1]\n",
    "\n",
    "    parcel_list = [x for x in  os.listdir(spath+'/parcel_matrix/') if 'correlation' in x]\n",
    "    parcel_names = [x.split('_')[0] for x in parcel_list]\n",
    "\n",
    "    results_df = pd.DataFrame(columns=[['constant','conflict', 'watched', 'npeople', 'violence', 'ninteractions', 'feeling', 'tension', 'issocial']])\n",
    "\n",
    "    for p in parcel_list:\n",
    "        parcel_df = pd.read_csv(spath+'/parcel_matrix/'+p, header=None)\n",
    "        y = nilearn.connectome.sym_matrix_to_vec(np.array(parcel_df), discard_diagonal=True) # lower triangle\n",
    "\n",
    "        all_iv = np.empty((45,8))\n",
    "        \n",
    "        for i in range(len(iv_list)):\n",
    "            df = iv_list[i]\n",
    "            filtered_df = df[(df.movie == smovie)]\n",
    "            col = [str(x) for x in list(filtered_df.index)]\n",
    "            \n",
    "            x_100 = filtered_df.drop(['movieID','movie'], axis=1)\n",
    "            x = x_100[col]\n",
    "            x_lower = nilearn.connectome.sym_matrix_to_vec(np.array(x), discard_diagonal=True) # lower triangle\n",
    "\n",
    "            all_iv[:,i] = x_lower\n",
    "        \n",
    "        all_iv = sm.add_constant(all_iv)\n",
    "        regression = sm.OLS(y,all_iv)\n",
    "        results = regression.fit()\n",
    "\n",
    "        results_df.loc[len(results_df)] = results.params\n",
    "    \n",
    "    results_df['subject'] = s\n",
    "    results_df['movie'] = smovie\n",
    "    results_df['parcel'] = parcel_names\n",
    "    \n",
    "\n",
    "    results_df.to_csv(spath+'/results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3951f968",
   "metadata": {},
   "source": [
    "### <font color='deeppink'> Calculating Cohen's d</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ec579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dde295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/derivatives/\"\n",
    "\n",
    "sub_list = os.listdir(derivatives)\n",
    "sub_list = [x for x in sub_list if 'sub' in x] #remove hidden files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7ddbfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bof = []\n",
    "\n",
    "# for s in sub_list:\n",
    "#     spath = derivatives+s\n",
    "#     bof.append(pd.read_csv(spath+'/results.csv'))\n",
    "\n",
    "# results = pd.concat(bof)\n",
    "# results.reset_index(inplace=True, drop=True)\n",
    "# results.drop(['Unnamed: 0'],inplace=True, axis=1)\n",
    "# results.to_csv(derivatives+\"/complete_betas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56eed891",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(derivatives+'/complete_betas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b107dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert betas to cohen's d value -- done\n",
    "\n",
    "out = pd.DataFrame(columns=[['conflict', 'watched', 'npeople', 'violence', 'ninteractions', 'feeling', 'tension', 'issocial']])\n",
    "\n",
    "for i in range(400):\n",
    "    parcel = results.loc[results.parcel == i]\n",
    "\n",
    "    cols = ['conflict', 'watched', 'npeople', 'violence', 'ninteractions', 'feeling', 'tension', 'issocial']\n",
    "    dvals = []\n",
    "    \n",
    "    for col in cols:\n",
    "        dvals.append(parcel[col].mean()/ parcel[col].std())\n",
    "\n",
    "    out.loc[len(out)] = dvals\n",
    "\n",
    "out.to_csv(derivatives+'/parcel_cohensd.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca27a96",
   "metadata": {},
   "source": [
    "### <font color='deeppink'> Permutation Analyses</font>\n",
    "\n",
    "Next, we will bootstrap the participants and permute the cohen's d values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fac6943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "derivatives = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/derivatives/\"\n",
    "\n",
    "sub_list = os.listdir(derivatives)\n",
    "sub_list = [x for x in sub_list if 'sub' in x] #remove hidden files\n",
    "\n",
    "results = pd.read_csv(derivatives+'/complete_betas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f25c6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_mat = np.empty((400,1000,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dd896c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['conflict', 'watched', 'npeople', 'violence', 'ninteractions', 'feeling', 'tension', 'issocial']\n",
    "\n",
    "for i in range(400)[0:5]:\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    parcel = results.loc[results.parcel == i]\n",
    "\n",
    "    #bootstrap and permute the parcel dataframe\n",
    "    for p in range():\n",
    "\n",
    "        boot_sample = parcel.sample(n=86, replace=True)\n",
    "        boot_movies = boot_sample['movie'].unique() # an array of movie names\n",
    "\n",
    "        #set up the sign flipping for each parcel sample's set of movies:\n",
    "        signs_arr = np.random.choice((-1,1), len(boot_movies), replace=True) # returns an array of 1's and -1's\n",
    "        \n",
    "        for ix, movie in enumerate(boot_movies): #create the sign-flipped dataframe\n",
    "\n",
    "            filtered = boot_sample[(boot_sample.movie == movie)]\n",
    "            filtered.loc[:, columns] = filtered[columns].apply(lambda x: x * signs_arr[ix], axis=1)\n",
    "            boot_sample[(boot_sample.movie == movie)] = filtered\n",
    "\n",
    "        #now with the bootstrap and the permutation orders set up, calculate new cohen d values:\n",
    "        perm_mat[i,p] = np.array(np.mean(boot_sample[columns],axis=0)/np.std(boot_sample[columns],axis=0))\n",
    "\n",
    "np.save(derivatives+'/permutation_matrix', perm_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "201cf27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_maxes = np.max(np.abs(perm_mat), axis=1)\n",
    "absmaxes_df = pd.DataFrame(abs_maxes)\n",
    "absmaxes_df.to_csv(derivatives+'/permuted_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Bash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
