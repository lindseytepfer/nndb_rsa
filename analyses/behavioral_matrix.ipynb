{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12558b9f",
   "metadata": {},
   "source": [
    "# Creating a similarity matrix from behavioral ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b437151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ec5d4",
   "metadata": {},
   "source": [
    "### <font color='hotpink'>Preprocess data </font>\n",
    "Here, we want to compute the average ratings made by CloudResearch participants across a number of variables: how much interpersonal conflict, tension, or violence was present in the scene (each on a scale of 1-7, 7 being the highest amount), whether or not there was a social interaction present in the clip, how many people were present in the clip, how many people were actually interacting in the clip, whether they had seen that particular scene before, and how positive or negative the clip made them feel (1 is very negative and 7 is very positive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232790f6-8b48-40d0-84f4-e893357adeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nndb_raters_responses_cleaned.csv')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c73d83ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for 'watched' and 'social'\n",
    "\n",
    "def dummy_variable(dataframe, column, value_to_replace, replacement_value):\n",
    "    for i in range(dataframe.index.max()+1):\n",
    "        if dataframe.loc[i, str(column)] == value_to_replace:\n",
    "            dataframe.loc[i, str(column)] = replacement_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75504e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variable(df, \"social\", 'yes', 1)\n",
    "dummy_variable(df, \"social\", 'no', 0)\n",
    "dummy_variable(df, \"watched\", 'Yes', 1)\n",
    "dummy_variable(df, \"watched\", 'No', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd0deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_merge(dataframe):\n",
    "    avg_subset = dataframe[['watched', 'social', 'feeling', 'tension', 'conflict','violence', 'movieID']]\n",
    "    df1 = avg_subset.groupby('movieID').mean().reset_index()\n",
    "\n",
    "    median_subset = dataframe[['count_people','count_interactions','movieID']]\n",
    "    df2 = median_subset.groupby('movieID').median().reset_index()\n",
    "\n",
    "    joined = pd.merge(df1, df2, how='left', left_on=['movieID'], right_on=['movieID'])\n",
    "\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff775f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDon't re-generate; I added leading zeroes in the movie IDs with timestamps that \\nwere fewer than 4 integer lengths to allow filenames to be sorted numerically.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = group_and_merge(df)\n",
    "\n",
    "#add a column for movie name only \n",
    "for i in range(results_df.index.max()+1):\n",
    "\n",
    "    clip = results_df.loc[i, \"movieID\"]\n",
    "    movie = clip.split('_')[0]\n",
    "    results_df.loc[i, \"movie\"] = movie\n",
    "\n",
    "\n",
    "'''\n",
    "Don't re-generate; I added leading zeroes in the movie IDs with timestamps that \n",
    "were fewer than 4 integer lengths to allow filenames to be sorted numerically.\n",
    "'''\n",
    "# results_df.to_csv(\"movie_tcv_ratings.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd54258",
   "metadata": {},
   "source": [
    "### <font color='hotpink'>Calculate inter-rater reliability</font>\n",
    "We collected a total of 150 participant ratings. Clips were randomly presented, and as such we have variation among participants with how they might have rated each clip. In this next section, we look to determine how reliable our clip ratings are by performing a repeated split half approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "effb9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "968b4435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to compare by movie! otherwise correlation is very low.\n",
    "\n",
    "col_list = ['watched', 'social', 'feeling', 'tension', 'conflict','violence','count_people','count_interactions']\n",
    "corr_df = pd.DataFrame(columns=col_list)\n",
    "\n",
    "#set a random seed to ensure reproducibility \n",
    "random.seed(0)\n",
    "\n",
    "for i in range(0,100):\n",
    "    subject_list = df['userID'].unique()\n",
    "\n",
    "    random.shuffle(subject_list)\n",
    "\n",
    "    half = len(subject_list) // 2\n",
    "\n",
    "    split1 = df[df['userID'].isin(subject_list[:half])]\n",
    "    split2 = df[df['userID'].isin(subject_list[half:])]\n",
    "\n",
    "    split1_calc = group_and_merge(split1)\n",
    "    split2_calc = group_and_merge(split2)\n",
    "\n",
    "    i_corr = []\n",
    "\n",
    "    for col in col_list:\n",
    "        i_corr.append(split1_calc[col].corr(split2_calc[col]))\n",
    "    \n",
    "    corr_df.loc[len(corr_df.index)] = i_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae822656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watched SBP:  0.6052765877278105\n",
      "social SBP:  0.4212931971906028\n",
      "feeling SBP:  0.7648424106343414\n",
      "tension SBP:  0.7763123108119593\n",
      "conflict SBP:  0.7940296653447201\n",
      "violence SBP:  0.7599714787542613\n",
      "count_people SBP:  0.813926604566568\n",
      "count_interactions SBP:  0.6832710232482896\n"
     ]
    }
   ],
   "source": [
    "for i in corr_df.columns:\n",
    "    r = corr_df[i].mean()\n",
    "    print(i,  \"SBP: \", 2*r/(1+r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc1f7a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watched 0.43397607181608466\n",
      "social 0.26685968315388775\n",
      "feeling 0.6192265806561108\n",
      "tension 0.6344039559040341\n",
      "conflict 0.6584155866252623\n",
      "violence 0.6128661282651712\n",
      "count_people 0.686236288327782\n",
      "count_interactions 0.5189154604418879\n"
     ]
    }
   ],
   "source": [
    "for i in corr_df.columns:\n",
    "    r = corr_df[i].mean()\n",
    "    print(i, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12609f8b",
   "metadata": {},
   "source": [
    "<font color='deeppink'>Reveal clips that have low agreement on whether or not the clip contains a social interaction:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ea90a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clip: citizenfour_2373_2390 has low agreement level:  0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "for i in range(results_df.index.max()+1):\n",
    "    if results_df.loc[i, \"social\"] <= 0.5:\n",
    "        print(\"Clip:\",results_df.loc[i, \"movieID\"], \"has low agreement level: \", results_df.loc[i, \"social\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2b6a42",
   "metadata": {},
   "source": [
    "<font color='deeppink'>Evaluate wheter there are meaningful differences between those who have watched the film vs those who have not.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc7f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list2 = ['social', 'feeling', 'tension', 'conflict','violence','count_people','count_interactions']\n",
    "\n",
    "watched = df[df.watched == 1].reset_index()\n",
    "unwatched = df[df.watched == 0].reset_index()\n",
    "\n",
    "watched_split = group_and_merge(watched)\n",
    "unwatched_split = group_and_merge(unwatched)\n",
    "\n",
    "for i in range(unwatched_split.index.max()+1):\n",
    "    \n",
    "    clip = unwatched_split.loc[i, \"movieID\"]\n",
    "    \n",
    "    if clip not in watched_split.movieID.unique(): \n",
    "        unwatched_split.drop(i, axis=0, inplace=True)\n",
    "    \n",
    "unwatched_split.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf5fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure the columns are aligned\n",
    "\n",
    "for i in range(watched_split.index.max()+1):\n",
    "    if watched_split.loc[i, \"movieID\"] != unwatched_split.loc[i, \"movieID\"]:\n",
    "        print(watched_split.loc[i, \"movieID\"])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "#they are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7ebcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>social</th>\n",
       "      <td>-0.042998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feeling</th>\n",
       "      <td>0.609194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tension</th>\n",
       "      <td>0.542284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conflict</th>\n",
       "      <td>0.648338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violence</th>\n",
       "      <td>0.633678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_people</th>\n",
       "      <td>0.682536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_interactions</th>\n",
       "      <td>0.510198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "social             -0.042998\n",
       "feeling             0.609194\n",
       "tension             0.542284\n",
       "conflict            0.648338\n",
       "violence            0.633678\n",
       "count_people        0.682536\n",
       "count_interactions  0.510198"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watched_df = pd.DataFrame(columns=col_list2)\n",
    "\n",
    "w_corr = []\n",
    "\n",
    "for col in col_list2:\n",
    "    w_corr.append(watched_split[col].corr(unwatched_split[col]))\n",
    "\n",
    "watched_df.loc[len(watched_df.index)] = w_corr\n",
    "\n",
    "watched_df.T\n",
    "#pretty nicely correlated, which is encouraging!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8baf7a-899c-4edd-8c95-1cad84122101",
   "metadata": {},
   "source": [
    "# <font color='deeppink'>Generating a similarity matrix</font>\n",
    "Now that we've checked for reliability among our participants, we want to construct a similarity matrix between each movie clip for all 8 types of ratings. So, for example, we want to see how \"far apart\" clip_1 is to clip_10 on tension, as well as violence, and so on. We will use these matrices as predictors for neural data later in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d7d1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68d25c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives = \"/Users/f004p74/Documents/dartmouth/projects/NNDb/derivatives/\"\n",
    "\n",
    "df = pd.read_csv(\"movie_tcv_ratings.csv\")\n",
    "df.sort_values(by=['movieID'], ascending=True, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "col_list = ['watched', 'social', 'feeling', 'tension', 'conflict', 'violence', 'count_people', 'count_interactions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "651df03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_list:\n",
    "    arr = np.array(df[col])\n",
    "    arr = arr.reshape(-1,1)\n",
    "\n",
    "    distance_matrix = pairwise_distances(arr)\n",
    "\n",
    "    distance_df = pd.DataFrame(distance_matrix)\n",
    "\n",
    "    labels = df[['movieID', 'movie']]\n",
    "\n",
    "    new_df = pd.concat([labels, distance_df], axis=1)\n",
    "\n",
    "    #new_df.to_csv(derivatives+\"behavioral_matrices/\"+col+\"_distance_matrix.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
